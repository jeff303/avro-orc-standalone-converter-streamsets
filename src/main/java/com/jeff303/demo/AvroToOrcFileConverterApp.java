/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.jeff303.demo;

import com.streamsets.pipeline.lib.util.avroorc.AvroToOrcRecordConverter;
import org.apache.hadoop.conf.Configuration;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Properties;

public class AvroToOrcFileConverterApp {
  public static void main(String[] args) throws IOException {
    if (args == null || args.length != 2) {
      System.err.printf("Usage: %s <input Avro file> <output ORC file>%n", AvroToOrcFileConverterApp.class.getName());
      System.exit(1);
    }

    final String avroFile = args[0];
    final Path avroFilePath = Paths.get(avroFile);
    if (!avroFilePath.toFile().exists()) {
      System.err.printf("Input Avro file %s is not a regular file; cannot convert%n", avroFile);
      System.exit(2);
    }

    final String orcFile = args[1];
    final Path orcFilePath = Paths.get(orcFile);
    if (Files.exists(orcFilePath)) {
      System.err.printf("Output ORC file %s already exists; it will be overwritten%n", orcFile);
      Files.delete(orcFilePath);
    }

    final Properties orcWriterProperties = new Properties();
    final Configuration hadoopConf = new Configuration();

    AvroToOrcRecordConverter converter = new AvroToOrcRecordConverter(10000, orcWriterProperties, hadoopConf);

    try {
      converter.convert(avroFile, orcFile);
    } catch (Exception e) {
      e.printStackTrace();
    }
  }
}
